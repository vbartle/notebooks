{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import text and label data by passing file paths into the pandas read_csv function. This data can be downloaded from: https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon, imdb, yelp = [pd.read_csv('labeled_sent_data/'+str(i)+'.txt', sep=\"\\t\", header=None) \n",
    "                      for i in ['amazon','imdb','yelp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>The screen does get smudged easily because it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>What a piece of junk.. I lose more calls on th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Item Does Not Match Picture.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The only thing that disappoint me is the infra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>You can not answer calls with the unit, never ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  1\n",
       "0    So there is no way for me to plug it in here i...  0\n",
       "1                          Good case, Excellent value.  1\n",
       "2                               Great for the jawbone.  1\n",
       "3    Tied to charger for conversations lasting more...  0\n",
       "4                                    The mic is great.  1\n",
       "..                                                 ... ..\n",
       "995  The screen does get smudged easily because it ...  0\n",
       "996  What a piece of junk.. I lose more calls on th...  0\n",
       "997                       Item Does Not Match Picture.  0\n",
       "998  The only thing that disappoint me is the infra...  0\n",
       "999  You can not answer calls with the unit, never ...  0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then combine our three data sources since we are not interested in comparing the separate datasets to each other in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2748 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "0    So there is no way for me to plug it in here i...      0\n",
       "1                          Good case, Excellent value.      1\n",
       "2                               Great for the jawbone.      1\n",
       "3    Tied to charger for conversations lasting more...      0\n",
       "4                                    The mic is great.      1\n",
       "..                                                 ...    ...\n",
       "995  I think food should have flavor and texture an...      0\n",
       "996                           Appetite instantly gone.      0\n",
       "997  Overall I was not impressed and would not go b...      0\n",
       "998  The whole experience was underwhelming, and I ...      0\n",
       "999  Then, as if I hadn't wasted enough of my life ...      0\n",
       "\n",
       "[2748 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumData = pd.concat([amazon,imdb,yelp])\n",
    "sumData.columns = ['text','label']\n",
    "sumData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then want to clean the text data to be lowercase, without punctuation, and without braces or numbers, generally this information does not contribute to analysis although it may be in more complicated text analysis methods. We can clean our data using `Regular Expressions` which are character mappings for finding patterns in text, we also import `string` which is a native python library with a set of string types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    text=text.lower()\n",
    "    # regex\n",
    "    text = re.sub('\\[.*?\\]', '', text) # remove text in brackets\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # remove punctuation\n",
    "    text = re.sub('\\w*\\d\\w*', '', text) # remove words with numbers in them\n",
    "    return text\n",
    "\n",
    "cleaningRound = lambda x: cleanText(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas includes functionality to map data through a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedData = pd.DataFrame(sumData.text.apply(cleaningRound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good case excellent value</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great for the jawbone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the mic is great</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>i think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>appetite instantly gone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>overall i was not impressed and would not go back</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>the whole experience was underwhelming and i t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>then as if i hadnt wasted enough of my life th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2748 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "0    so there is no way for me to plug it in here i...      0\n",
       "1                            good case excellent value      1\n",
       "2                                great for the jawbone      1\n",
       "3    tied to charger for conversations lasting more...      0\n",
       "4                                     the mic is great      1\n",
       "..                                                 ...    ...\n",
       "995  i think food should have flavor and texture an...      0\n",
       "996                            appetite instantly gone      0\n",
       "997  overall i was not impressed and would not go back      0\n",
       "998  the whole experience was underwhelming and i t...      0\n",
       "999  then as if i hadnt wasted enough of my life th...      0\n",
       "\n",
       "[2748 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumData.text = cleanedData # We replace the text column with our cleaned text data column.\n",
    "sumData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before performing any kind of training or analysis on our data, we want to partition a segment of it to test our trained model on, so we split our data into training and testing, and ensure that this partition select uniformally and randomly throughout our entire dataset. `sklearn` provides a function that handles this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>what should have been a hilarious yummy christ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>this is by far the worst purchase ive made on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>the bipolarity of the ruthless thug one minute...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>if someone orders two tacos dont you think it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>i checked out this place a couple years ago an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>all it took was one drop from about  inches ab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>when achille and philippa beautifully sing a d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>motorola finally got the voice quality of a bl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>i have used several phone in two years but thi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not tasty and the texture was just nasty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "919  what should have been a hilarious yummy christ...      0\n",
       "875  this is by far the worst purchase ive made on ...      0\n",
       "348  the bipolarity of the ruthless thug one minute...      0\n",
       "961  if someone orders two tacos dont you think it ...      0\n",
       "611  i checked out this place a couple years ago an...      0\n",
       "..                                                 ...    ...\n",
       "535  all it took was one drop from about  inches ab...      0\n",
       "614  when achille and philippa beautifully sing a d...      1\n",
       "925  motorola finally got the voice quality of a bl...      1\n",
       "415  i have used several phone in two years but thi...      1\n",
       "2             not tasty and the texture was just nasty      0\n",
       "\n",
       "[2198 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,test = train_test_split(sumData, test_size=.2)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>disappointment i hate anything that goes in my...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>awkward to use and unreliable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>you wont regret it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>it is cheap and it feel and look just as cheap</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>absolutel junk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>i had high hopes for this place since the burg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>overall i was very disappointed with the quali...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>we started with the tuna sashimi which was bro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>worthwhile</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>anyways the food was definitely not filling at...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "472  disappointment i hate anything that goes in my...      0\n",
       "824                      awkward to use and unreliable      0\n",
       "496                               you wont regret it        1\n",
       "608     it is cheap and it feel and look just as cheap      0\n",
       "263                                     absolutel junk      0\n",
       "..                                                 ...    ...\n",
       "805  i had high hopes for this place since the burg...      0\n",
       "401  overall i was very disappointed with the quali...      0\n",
       "981  we started with the tuna sashimi which was bro...      0\n",
       "777                                         worthwhile      1\n",
       "699  anyways the food was definitely not filling at...      0\n",
       "\n",
       "[550 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now looking for a way to interpret our text data numerically, which will let us build a model to differentiate between all phrases.\n",
    "\n",
    "The method used below builds a dictionary of unique words used in the entire dataset, sets each word as a column of a matrix, and then represents each phrase in the dataset as a row where cell values start at zero and increment for each vocabulary used throughout the columns -- essentially providing a frequency table of words for every phrase.\n",
    "\n",
    "`sklearn` provides a `vectorizer` that handles this, and additionally removes conjunctions like `a, the, and` which similar to our cleaning step above, removes data that does not contribute to this analysis. One step more complicated that isn't done below, is to increment counts for excessively frequent words or weigh words with excessive counts less heavily. A dataset on film or food for instance might use the words 'film' and 'food' conjunctively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainVectorizer = CountVectorizer()\n",
    "fittedTrainVectors = TrainVectorizer.fit_transform(train.text).todense()\n",
    "fittedTrainVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above builds our vectors and dictionary. To create the vectors of our test dataset we don't want to include any more vocabulary and in fact want to use the exact same vocabulary that was built during our training. So we can pass the vocabulary found during the vectorizing step above to produce our testing vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aailiyah',\n",
       " 'abandoned',\n",
       " 'abhor',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abound',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absolutely']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainVectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice the train vocabulary being passed in.\n",
    "TestVectorizer = CountVectorizer(vocabulary = TrainVectorizer.get_feature_names()) \n",
    "fittedTestVectors = TestVectorizer.transform(test.text).todense()\n",
    "fittedTestVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now interested in classifying our vectors. One way to intuit this step is in the 2d linear regression example, where given points of two colors, scattered on an x,y plane, we are interested in finding a line of the form $y=mx+b$ that best segregates the points by finding the best parameters for $m$ and $b$. In this example though, we are building a polynomial line and have an n-dimensional space that correlates to how many vocabulary words, also known as features, were found in the vectorizing step. `sklearn` has a logistic regression model that can handle this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentClassifier(trainData, trainLabel, testData, testLabel):\n",
    "    classification = LogisticRegression().fit(trainData, trainLabel)\n",
    "    classificationScore = classification.score(testData, testLabel)\n",
    "    return classification,classificationScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = sentClassifier(fittedTrainVectors, train['label'].ravel(),\n",
    "                                 fittedTestVectors, test['label'].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(), 0.8036363636363636)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a trained model and an accuracy score for our model build by comparing the predicted classification with the actual label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7981818181818182"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "results = classifications[0].predict(fittedTestVectors) == test['label'].ravel()\n",
    "np.unique(results, return_counts=True)\n",
    "439/550"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see all the instances wherein it failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, False],\n",
       " [12, False],\n",
       " [43, False],\n",
       " [47, False],\n",
       " [48, False],\n",
       " [57, False],\n",
       " [58, False],\n",
       " [59, False],\n",
       " [60, False],\n",
       " [68, False]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fails = [[i,j] for i,j in enumerate(results) if j == False]\n",
    "fails[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if you act in such a film you should be glad that youre gonna drift away from earth as far as possible  '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'].iloc[41]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage the best course of increased accuracy is to weigh words more heavily based on their context. The typical failure will be due to the nature of simply looking at each individual word and seeing if it was in a negatively or positively labeled sentence, regardless of the context. \n",
    "\n",
    "We can also see how certain the model was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56236905, 0.43763095])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "certainties = classifications[0].predict_proba(fittedTestVectors)\n",
    "certainties[41]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presumeably, the above sentence does not mention the words \"good\" or \"bad\" or any clear polarizer along those lines, so the model was fairly ambiguous about it's sentiment. \n",
    "\n",
    "We can also build Bag of Words and Logistic Regression from scratch rather than use `sklearn` for these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aailiyah</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abhor</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abound</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>...</th>\n",
       "      <th>youthful</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youve</th>\n",
       "      <th>yucky</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yun</th>\n",
       "      <th>zero</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombiestudents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2198 rows × 4699 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aailiyah  abandoned  abhor  ability  able  abound  about  above  abroad  \\\n",
       "0            0          0      0        0     0       0      0      0       0   \n",
       "1            0          0      0        0     0       0      0      0       0   \n",
       "2            0          0      0        0     0       0      0      0       0   \n",
       "3            0          0      0        0     0       0      0      0       0   \n",
       "4            0          0      0        0     0       0      0      0       0   \n",
       "...        ...        ...    ...      ...   ...     ...    ...    ...     ...   \n",
       "2193         0          0      0        0     0       0      1      1       0   \n",
       "2194         0          0      0        0     0       0      0      0       0   \n",
       "2195         0          0      0        0     0       0      0      0       0   \n",
       "2196         0          0      0        0     0       0      0      0       0   \n",
       "2197         0          0      0        0     0       0      0      0       0   \n",
       "\n",
       "      absolutely  ...  youthful  youtube  youve  yucky  yummy  yun  zero  \\\n",
       "0              0  ...         0        0      0      0      1    0     0   \n",
       "1              0  ...         0        0      0      0      0    0     0   \n",
       "2              0  ...         0        0      0      0      0    0     0   \n",
       "3              0  ...         0        0      0      0      0    0     0   \n",
       "4              0  ...         0        0      0      0      0    0     0   \n",
       "...          ...  ...       ...      ...    ...    ...    ...  ...   ...   \n",
       "2193           0  ...         0        0      0      0      0    0     0   \n",
       "2194           0  ...         0        0      0      0      0    0     0   \n",
       "2195           0  ...         0        0      0      0      0    0     0   \n",
       "2196           0  ...         0        0      0      0      0    0     0   \n",
       "2197           0  ...         0        0      0      0      0    0     0   \n",
       "\n",
       "      zillion  zombie  zombiestudents  \n",
       "0           0       0               0  \n",
       "1           0       0               0  \n",
       "2           0       0               0  \n",
       "3           0       0               0  \n",
       "4           0       0               0  \n",
       "...       ...     ...             ...  \n",
       "2193        0       0               0  \n",
       "2194        0       0               0  \n",
       "2195        0       0               0  \n",
       "2196        0       0               0  \n",
       "2197        0       0               0  \n",
       "\n",
       "[2198 rows x 4699 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagOfWords = pd.DataFrame(fittedTrainVectors)\n",
    "bagOfWords.columns = TrainVectorizer.get_feature_names()\n",
    "bagOfWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at an individual phrase and see how it was vectorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the bipolarity of the ruthless thug one minute a ruthless killer the next minute a luvs diaper commercial is completely unconvincing  '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[377, 1],\n",
       " [774, 1],\n",
       " [793, 1],\n",
       " [1090, 1],\n",
       " [2144, 1],\n",
       " [2232, 1],\n",
       " [2418, 1],\n",
       " [2573, 2],\n",
       " [2711, 1],\n",
       " [2777, 1],\n",
       " [2799, 1],\n",
       " [3443, 2],\n",
       " [4090, 3],\n",
       " [4146, 1],\n",
       " [4308, 1]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[ind,i] for ind,i in enumerate(bagOfWords.iloc[2]) if i>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bipolarity', 'commercial', 'completely', 'diaper', 'is', 'killer',\n",
       "       'luvs', 'minute', 'next', 'of', 'one', 'ruthless', 'the', 'thug',\n",
       "       'unconvincing'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagOfWords.columns[[ind for ind,i in enumerate(bagOfWords.iloc[2]) if i>0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is code for building logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent to optimize function\n",
    "# Could do at least one whole session on this, if not several\n",
    "def gradient_descent(X, y, params, learning_rate, iterations):\n",
    "    m = len(y)\n",
    "    cost_history = np.zeros((iterations,1))\n",
    "\n",
    "    for i in range(iterations):\n",
    "        params = params - (learning_rate/m) * (X.T @ (sigmoid(X @ params) - y)) \n",
    "        cost_history[i] = compute_cost(X, y, params)\n",
    "\n",
    "    return (cost_history, params)\n",
    "# Logistic regression cost function\n",
    "def compute_cost(X,y,theta):\n",
    "    m = len(y)\n",
    "    h = sigmoid(X@ theta)\n",
    "    epsilon = 1e-5\n",
    "    cost = (1/m)*(((-y).T @ np.log(h + epsilon))-((1-y).T @ np.log(1-h + epsilon)))\n",
    "    return cost\n",
    "# https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html#cost-function\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "# https://mathworld.wolfram.com/SigmoidFunction.html\n",
    "def predict(X, params):\n",
    "    return np.round(sigmoid(X @ params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to find parameters for a best fit classifier \"line\" that can segregate positive and negative labels well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.vstack(train['label'].ravel())\n",
    "X = fittedTrainVectors\n",
    "m = len(y)\n",
    "X = np.hstack((np.ones((m,1)),X))\n",
    "n = np.size(X,1)\n",
    "params = np.zeros((n,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4700, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08531973]\n",
      " [ 0.02823954]\n",
      " [-0.05334732]\n",
      " ...\n",
      " [-0.05363031]\n",
      " [ 0.00995256]\n",
      " [-0.04014604]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "iterations = 1000\n",
    "learning_rate = 0.3\n",
    "initial_cost = compute_cost(X, y, params)\n",
    "(cost_history, fittedParams) = gradient_descent(X, y, params, learning_rate, iterations)\n",
    "\n",
    "print(fittedParams, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4700, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(fittedParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the optimization process using matplotlib as the cost history saved above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1344b3b90>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(cost_history)), cost_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of iterations increases, the logistic nature of the graph above will get more and more pronounced. \n",
    "\n",
    "We can also see how well the above model performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9008189262966333\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X, fittedParams)\n",
    "score = float(sum(y_pred == y))/ float(len(y))\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as the certainty scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.31352975],\n",
       "        [0.20239158],\n",
       "        [0.2915797 ],\n",
       "        [0.11945554],\n",
       "        [0.2764864 ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unrounded = sigmoid(X @ fittedParams)\n",
    "unrounded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "919    0\n",
       "875    0\n",
       "348    0\n",
       "961    0\n",
       "611    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a repeated walk through of the vectorizing process, now with a single phrase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disappointment i hate anything that goes in my ear']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singleTest = [test['text'].iloc[0]]\n",
    "singleTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0', 'aailiyah'],\n",
       "       ['1', 'abandoned'],\n",
       "       ['2', 'abhor'],\n",
       "       ...,\n",
       "       ['4696', 'zillion'],\n",
       "       ['4697', 'zombie'],\n",
       "       ['4698', 'zombiestudents']], dtype='<U33')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.vstack([[ind,val] for ind,val in enumerate(bagOfWords.columns)])\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['170', 'anything'], dtype='<U33'),\n",
       " array(['1119', 'disappointment'], dtype='<U33'),\n",
       " array(['1242', 'ear'], dtype='<U33'),\n",
       " array(['1752', 'goes'], dtype='<U33'),\n",
       " array(['1858', 'hate'], dtype='<U33'),\n",
       " array(['2047', 'in'], dtype='<U33'),\n",
       " array(['2664', 'my'], dtype='<U33'),\n",
       " array(['4087', 'that'], dtype='<U33')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singleTestIndices = [i for i in vocab for j in singleTest[0].split() if i[1] == j]\n",
    "singleTestIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aailiyah', 0.0),\n",
       " ('abandoned', 0.0),\n",
       " ('abhor', 0.0),\n",
       " ('ability', 0.0),\n",
       " ('able', 0.0)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initDict = dict(zip(vocab[:,1],np.zeros(len(bagOfWords.columns))))\n",
    "list(initDict.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the frequency counting step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in singleTestIndices:\n",
    "    initDict[i[1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initDict['interesting'],initDict['bad'], initDict['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38295659693841266"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(pd.DataFrame.from_dict(initDict, orient='index').T@fittedParams[:len(fittedParams)-1]).iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications[0].predict(fittedTestVectors)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then condense the above to apply to any arbitrary phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifySingle(text):\n",
    "    vocab = np.vstack([[ind,val] for ind,val in enumerate(bagOfWords.columns)])\n",
    "    singleTestIndices = [i for i in vocab for j in text[0].split() if i[1] == j]\n",
    "    initDict = dict(zip(vocab[:,1],np.zeros(len(bagOfWords.columns))))\n",
    "    for i in singleTestIndices:\n",
    "        initDict[i[1]] += 1\n",
    "    result = sigmoid(pd.DataFrame.from_dict(initDict, orient='index').T@fittedParams[:len(fittedParams)-1])\n",
    "    if result.iloc[0][0] >= .5:\n",
    "        return text[0], \"Positive Sentiment: %1.2f%%\" % (result.iloc[0][0]*100)\n",
    "    else:\n",
    "        return text[0], \"Negative Sentiment: %1.2f%%\" % (result.iloc[0][0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['once there was a lovely little trashcan watching a big movie']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singleTest = ['once there was a lovely little trashcan watching a big movie']\n",
    "singleTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('once there was a lovely little trashcan watching a big movie',\n",
       " 'Positive Sentiment: 63.31%')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifySingle(singleTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I absolutely loved watching this movie', 'Positive Sentiment: 74.35%')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifySingle(['I absolutely loved watching this movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('computers bad rainbows good', 'Positive Sentiment: 54.85%')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifySingle(['computers bad rainbows good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ugly bad rainbows dog', 'Negative Sentiment: 42.66%')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifySingle(['ugly bad rainbows dog'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
